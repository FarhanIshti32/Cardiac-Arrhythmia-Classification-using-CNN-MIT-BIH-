{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization , GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "\n",
    "row_size = 128\n",
    "col_size = 128\n",
    "\n",
    "channels = 3\n",
    "image_shape = (row_size, col_size, channels)\n",
    "#image_shape = [128, 128]\n",
    "num_classes = 6\n",
    "\n",
    "\n",
    "#downloading base_model\n",
    "base_model= tf.keras.applications.VGG19(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=image_shape,\n",
    "    #pooling=None,\n",
    "    #classes=6,\n",
    "    #classifier_activation=\"softmax\",\n",
    ")\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to run the model in infrence mode to remove the effect of batch norm. then we need to fine tune the model.\n",
    "################################## this is the key. this freezes all the layers in the model one by one.\n",
    "for layer in base_model.layers:\n",
    "\tlayer.trainable = True\n",
    "##^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "top_model = base_model.output\n",
    "#top_model= GlobalAveragePooling2D()(top_model)\n",
    "top_model= Flatten()(top_model)\n",
    "top_model = Dense(4096,activation='relu')(top_model)\n",
    "top_model = Dropout(0.4)(top_model)\n",
    "top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=top_model)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "IMAGE_SIZE = [128, 128]\n",
    "\n",
    "gen = ImageDataGenerator(rescale=1./255,\n",
    "      #shear_range=0.2,\n",
    "      #zoom_range=0.2,\n",
    "      #vertical_flip=True,\n",
    "      horizontal_flip=True)\n",
    "\n",
    "train_path = 'F:\\Arrhythmia Detection\\Images\\All_images'\n",
    "gen = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "train_generator = gen.flow_from_directory(\n",
    "  train_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=True,\n",
    "  batch_size=batch_size,\n",
    "    subset='training' )\n",
    "\n",
    "valid_generator = gen.flow_from_directory(\n",
    "  train_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=True,\n",
    "  batch_size=batch_size,\n",
    "    subset='validation' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'F:\\Arrhythmia Detection\\VGG_arr_detection.h5'\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.1,\n",
    "                              patience = 1,\n",
    "                              verbose = 1,\n",
    "                              mode='min')\n",
    "csv_logger = CSVLogger(\"VGGmodel_history_log.csv\",separator=\",\", append=True)\n",
    "#csv_logger = CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint , csv_logger, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr = 1e-5)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = opt,\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  train_generator,\n",
    "  validation_data = valid_generator,\n",
    "  epochs=4,\n",
    "  steps_per_epoch=79866//batch_size,\n",
    "  validation_steps=19965//batch_size , callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Loss Curves\n",
    "#plt.figure(figsize=[10,8])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=12)\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    "plt.savefig(\"loss_densenet201.png\")\n",
    "plt.show()\n",
    " \n",
    "# Accuracy Curves\n",
    "#plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=12)\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)\n",
    "plt.savefig(\"acc_densenet201.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import pickle \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "path = 'F:/Arrhythmia Detection/Final_2_arr_detection.h5'\n",
    "#path = 'F:/CA Detection Github/ecg_model_own.hdf5'\n",
    "model =  load_model(path)\n",
    "gen = ImageDataGenerator()\n",
    "IMAGE_SIZE = [128 , 128 ]\n",
    "batch_size = 32\n",
    "\n",
    "t_path = 'F:/Arrhythmia Detection/Images/Test'\n",
    "\n",
    "test_generator = gen.flow_from_directory(\n",
    "  t_path,\n",
    "  target_size=IMAGE_SIZE,\n",
    "  shuffle=False)\n",
    "  #batch_size=batch_size,\n",
    "    #subset='validation' )\n",
    "\n",
    "class_labels = test_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "\n",
    "pred = model.predict(test_generator)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(test_generator.classes, pred, target_names=target_names))\n",
    "\n",
    "\n",
    "CM = confusion_matrix(test_generator.classes, pred)\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(12, 8))\n",
    "plt.xticks(range(6), [\"Normal ECG\" , \"PVC\" , \"PAB\" , \"RBB\" , \"LBB\" , \"APC\"], fontsize=16)\n",
    "plt.yticks(range(6), [\"Normal ECG\" , \"PVC\" , \"PAB\" , \"RBB\" , \"LBB\" , \"APC\"], fontsize=16)\n",
    "#plt.savefig(\"confusion matrix.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
